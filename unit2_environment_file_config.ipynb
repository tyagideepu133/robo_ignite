{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Environment File Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basis of OpenAI-Gym is the creation of a file called the <b>environment file</b>.\n",
    "\n",
    "This <b>environment file</b> will define how the learning file communicates with the OpenAI-Gym API.\n",
    "We will go over the environment file used for the turtlebot simulation throughout this entire course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to be clear, you are going to use the **gym_gazebo** module, not the original gym module. The reason is that in order to use Gazebo, this add-on had to be created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see where you can find these files.\n",
    "\n",
    "These files are part of the Python installation of the gym_gazebo module. So, the most desirable location to put them is in the **dist-packages** directory. In this case, you will find them in **\"/usr/local/lib/python2.7/dist-packages/,\"** inside the folder **gym_gazebo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"float:left;background: #407EAF\">\n",
    "<tr>\n",
    "<th>\n",
    "<p class=\"transparent\">Execute in WebShell #1</p>\n",
    "</th>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd /usr/local/lib/python2.7/dist-packages/gym_gazebo\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relevant things for now are the <i>**\\_\\_init\\_\\_.py**</i> file and the <i>**envs**</i> folder.\n",
    "<ul>\n",
    "    <li>\n",
    "    **\\_\\_init\\_\\_.py**: This file registers the different environments available in the gym infrastructure.<br>\n",
    "    \n",
    "    For the TurtleBot simulation, we set up different parameters; the most important ones being the **id** and the **timestep_limit**. The time step limit allows you to make the learning episodes shorter or longer, depending on your needs. For instance, if the action being performed is really short, decrease the time. On the other hand, if it's an action that needs more time to be performed properly, then increase the time step limit to allow the simulation to have time to perform the entire action.<br>\n",
    "    <p style=\"background:#CD2122;color:white;\">WARNING</p>\n",
    "    <br>\n",
    "    It's a very common error to put more time in the **timestep_limit** than afterwards, in the learning script maximum steps loop. This will result in the following error:<br><br>\n",
    "    <span style=\"color:red;\"><i><b>gym.error.Error: Tried to reset environment, which is not done</b></i><br></span>\n",
    "    <br>\n",
    "    So, always try to put the same value on both sides or more time on the learning script side. That way, it won't give this error that states that you have changed the episode without finishing. You have to make the timestep_limit equal or less than the total_time in the learning loop per episode. Never make the learning loop faster than the timestep_limit.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "register(\n",
    "    id='GazeboCircuitTurtlebotLidar-v0',\n",
    "    entry_point='gym_gazebo.envs:GazeboCircuitTurtlebotLidarEnv',\n",
    "    timestep_limit=1000,\n",
    "    reward_threshold=1.0,\n",
    "    nondeterministic = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>\n",
    "    **envs**: Inside this folder, you will find all the environment files defined. This is where you will have to put your own environment file for your simulation.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get inside the <i>envs</i> folder and open the env file <b>gazebo_circuit_turtlebot_lidar.py</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"float:left;background: #407EAF\">\n",
    "<tr>\n",
    "<th>\n",
    "<p class=\"transparent\">Execute in WebShell #1</p>\n",
    "</th>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd envs\n",
    "vim gazebo_circuit_turtlebot_lidar.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will get something similar to this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">**gazebo_circuit_turtlebot_lidar.py**</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import rospy\n",
    "import roslaunch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from gym import utils, spaces\n",
    "from gym_gazebo.envs import gazebo_env\n",
    "from geometry_msgs.msg import Twist\n",
    "from std_srvs.srv import Empty\n",
    "\n",
    "from sensor_msgs.msg import LaserScan\n",
    "\n",
    "from gym.utils import seeding\n",
    "\n",
    "class GazeboCircuitTurtlebotLidarEnv(gazebo_env.GazeboEnv):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Launch the simulation with the given launchfile name\n",
    "        gazebo_env.GazeboEnv.__init__(self, \"GazeboCircuitTurtlebotLidar_v0.launch\")\n",
    "        self.vel_pub = rospy.Publisher('/cmd_vel', Twist, queue_size=5)\n",
    "        self.unpause = rospy.ServiceProxy('/gazebo/unpause_physics', Empty)\n",
    "        self.pause = rospy.ServiceProxy('/gazebo/pause_physics', Empty)\n",
    "        self.reset_proxy = rospy.ServiceProxy('/gazebo/reset_simulation', Empty)\n",
    "\n",
    "        self.action_space = spaces.Discrete(3) #F,L,R\n",
    "        self.reward_range = (-np.inf, np.inf)\n",
    "\n",
    "        self._seed()\n",
    "\n",
    "    def discretize_observation(self,data,new_ranges):\n",
    "        discretized_ranges = []\n",
    "        min_range = 0.2\n",
    "        done = False\n",
    "        mod = len(data.ranges)/new_ranges\n",
    "        for i, item in enumerate(data.ranges):\n",
    "            if (i%mod==0):\n",
    "                if data.ranges[i] == float ('Inf'):\n",
    "                    discretized_ranges.append(6)\n",
    "                elif np.isnan(data.ranges[i]):\n",
    "                    discretized_ranges.append(0)\n",
    "                else:\n",
    "                    discretized_ranges.append(int(data.ranges[i]))\n",
    "            if (min_range > data.ranges[i] > 0):\n",
    "                done = True\n",
    "        return discretized_ranges,done\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def _step(self, action):\n",
    "\n",
    "        rospy.wait_for_service('/gazebo/unpause_physics')\n",
    "        try:\n",
    "            self.unpause()\n",
    "        except rospy.ServiceException, e:\n",
    "            print (\"/gazebo/unpause_physics service call failed\")\n",
    "\n",
    "        if action == 0: #FORWARD\n",
    "            vel_cmd = Twist()\n",
    "            vel_cmd.linear.x = 0.3\n",
    "            vel_cmd.angular.z = 0.0\n",
    "            self.vel_pub.publish(vel_cmd)\n",
    "        elif action == 1: #LEFT\n",
    "            vel_cmd = Twist()\n",
    "            vel_cmd.linear.x = 0.05\n",
    "            vel_cmd.angular.z = 0.3\n",
    "            self.vel_pub.publish(vel_cmd)\n",
    "        elif action == 2: #RIGHT\n",
    "            vel_cmd = Twist()\n",
    "            vel_cmd.linear.x = 0.05\n",
    "            vel_cmd.angular.z = -0.3\n",
    "            self.vel_pub.publish(vel_cmd)\n",
    "\n",
    "        data = None\n",
    "        while data is None:\n",
    "            try:\n",
    "                data = rospy.wait_for_message('/kobuki/laser/scan', LaserScan, timeout=5)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        rospy.wait_for_service('/gazebo/pause_physics')\n",
    "        try:\n",
    "            #resp_pause = pause.call()\n",
    "            self.pause()\n",
    "        except rospy.ServiceException, e:\n",
    "            print (\"/gazebo/pause_physics service call failed\")\n",
    "\n",
    "        state,done = self.discretize_observation(data,5)\n",
    "\n",
    "        if not done:\n",
    "            if action == 0:\n",
    "                reward = 5\n",
    "            else:\n",
    "                reward = 1\n",
    "        else:\n",
    "            reward = -200\n",
    "\n",
    "        return state, reward, done, {}\n",
    "\n",
    "    def _reset(self):\n",
    "\n",
    "        # Resets the state of the environment and returns an initial observation.\n",
    "        rospy.wait_for_service('/gazebo/reset_simulation')\n",
    "        try:\n",
    "            #reset_proxy.call()\n",
    "            self.reset_proxy()\n",
    "        except rospy.ServiceException, e:\n",
    "            print (\"/gazebo/reset_simulation service call failed\")\n",
    "\n",
    "        # Unpause simulation to make observation\n",
    "        rospy.wait_for_service('/gazebo/unpause_physics')\n",
    "        try:\n",
    "            #resp_pause = pause.call()\n",
    "            self.unpause()\n",
    "        except rospy.ServiceException, e:\n",
    "            print (\"/gazebo/unpause_physics service call failed\")\n",
    "\n",
    "        #read laser data\n",
    "        data = None\n",
    "        while data is None:\n",
    "            try:\n",
    "                data = rospy.wait_for_message('/kobuki/laser/scan', LaserScan, timeout=5)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        rospy.wait_for_service('/gazebo/pause_physics')\n",
    "        try:\n",
    "            #resp_pause = pause.call()\n",
    "            self.pause()\n",
    "        except rospy.ServiceException, e:\n",
    "            print (\"/gazebo/pause_physics service call failed\")\n",
    "\n",
    "        state = self.discretize_observation(data,5) \n",
    "\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">**gazebo_circuit_turtlebot_lidar.py**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Python file, the **GazeboCircuitTurtlebotLidarEnv(gazebo_env.GazeboEnv)** class is defined.\n",
    "\n",
    "The main functions of this class are:<br>\n",
    "<ul>\n",
    "    <li>**\\_\\_init\\_\\_**: Here, all of the topics for communication with ROS are defined. Three of them are for resetting and pausing the simulation. This is used for resetting the simulation when the learning considers that it's in a bad configuration. And the pause is used in each step to simulate in steps and not lose any kind of data that could be generated between learning steps. It also defines a publisher to the **/cmd_vel** topic that will move the robot.<br><br> </li>\n",
    "    <li>\n",
    "    **\\_step**: Here, you define what will be performed in each learning step. It has as input an **action** variable that contains the action that the learning script considers it has to perform. It's here that each action is really defined. In this case, there are three actions available: **\"TURN LEFT,\"** **\"TURN RIGHT,\"** and **\"GO FORWARD.\"**<br><br>\n",
    "    \n",
    "    It also defines when the episode will be considered done based on, in this case, the readings of the laser. In this case, an episode is considered done when one of the laser readings is lower than 0.2. This means that the robot is really close to a wall and it is considered to be unsuccessful in accomplishing the learning goal, so a reset is needed to start another learning episode.<br><br>\n",
    "    Also, there are the rewards for performing each action. These rewards are necessary for the learning algorithms. In this case, the rewards are 5 if it hasn't run into a wall and is going forward, 1 if it hasn't run into a wall and is turning, and -200 if it has run into a wall.<br>    \n",
    "    </li>\n",
    "    <li>\n",
    "    **discretize_observation**: This function cleans up the laser readings. It returns a state variable where there is a discretized version of the laser readings. The laser range readings have got one laser reading for every five real ones. It has also converted Infinite distance readings to 6 and Null reading to 0. All of the other readings have been converted to integers.<br>\n",
    "    It also returns a done variable that depends on if a certain distance was below the minimum desired.<br><br>\n",
    "    </li>\n",
    "    <li>\n",
    "    **\\_reset**: This function will be called each time a reset in the simulation environment is needed, probably because the robot has run into a wall or the time step limit has been reached. It reads the laser data, returning a discretized version through the state variable. It also sends a simulation reset call to the Gazebo simulator.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#EE9023;color:white;\">**Exercise 2.1**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new environment file in you **catkin_ws/src** directory. You can call this file **my_custom_env.py**. You can copy to this file the contents of the <a href=\"#env-file\">**gazebo_circuit_turtlebot_lidar.py**</a> file you have just checked. Now, let's do a couple of modifications so that your training script uses this new environment file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Modify the name of the class in the environment file. For instance, you can call it **MyCustomEnv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Â class GazeboCircuitTurtlebotLidarEnv(gazebo_env.GazeboEnv):\n",
    "class MyCustomEnv(gazebo_env.GazeboEnv):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Next, you will have to register your new environment. For that, you will first need to add a register function inside your environment script. It could be something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg = register(\n",
    "    id='MyCustom-v0',\n",
    "    entry_point='my_custom_env:MyCustomEnv',\n",
    "    timestep_limit=100,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add this function right above the class registration.\n",
    "\n",
    "In order to be able to call this register function, though, you will need to import it first. So, add the following import to your file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gym.envs.registration import register"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Also, you will have to remove the line where the ROS node is started. This line is the following one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gazebo_env.GazeboEnv.__init__(self, \"GazeboCircuitTurtlebotLidar_v0.launch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, remove or comment this line.\n",
    "\n",
    "d) Finally, you will have to start this new environment in your learning script. So, open the my_simple_learning_turtlebot.py file, and modify the line where you initialize the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#env = gym.make('GazeboCircuitTurtlebotLidar-v0')\n",
    "env = gym.make('MyCustom-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, in order to be able to use this environment, you will have to import it first. So, add the following import to your file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import my_custom_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) There's one last thing to do. Start a ROS node in your learning script, right above the line where the environment is started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rospy.init_node('turtle_gym', anonymous=True) #This is the line you have to add\n",
    "env = gym.make('MyCustom-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) And that's it! Launch your learning script and check that everything works fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#EE9023;color:white;\">**END of Exercise 2.1**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">Solution Exercise 2.1</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please Try to do it by yourself unless you get stuck or need some inspiration. You will learn much more if you fight for each exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/robotignite_logo_text.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see how the final files should look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">**my_custom_env.py**</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import rospy\n",
    "import roslaunch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from gym import utils, spaces\n",
    "from gym_gazebo.envs import gazebo_env\n",
    "from geometry_msgs.msg import Twist\n",
    "from std_srvs.srv import Empty\n",
    "\n",
    "from sensor_msgs.msg import LaserScan\n",
    "\n",
    "from gym.utils import seeding\n",
    "from gym.envs.registration import register\n",
    "\n",
    "reg = register(\n",
    "    id='MyCustom-v0',\n",
    "    entry_point='my_custom_env:MyCustomEnv',\n",
    "    timestep_limit=100,\n",
    "    )\n",
    "\n",
    "class MyCustomEnv(gazebo_env.GazeboEnv):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.vel_pub = rospy.Publisher('/cmd_vel', Twist, queue_size=5)\n",
    "        self.unpause = rospy.ServiceProxy('/gazebo/unpause_physics', Empty)\n",
    "        self.pause = rospy.ServiceProxy('/gazebo/pause_physics', Empty)\n",
    "        self.reset_proxy = rospy.ServiceProxy('/gazebo/reset_simulation', Empty)\n",
    "        \n",
    "        #self.gazebo = GazeboConnection()\n",
    "\n",
    "        self.action_space = spaces.Discrete(3) #F,L,R\n",
    "        self.reward_range = (-np.inf, np.inf)\n",
    "\n",
    "        self._seed()\n",
    "\n",
    "    def discretize_observation(self,data,new_ranges):\n",
    "        discretized_ranges = []\n",
    "        min_range = 0.2\n",
    "        done = False\n",
    "        mod = len(data.ranges)/new_ranges\n",
    "        for i, item in enumerate(data.ranges):\n",
    "            if (i%mod==0):\n",
    "                if data.ranges[i] == float ('Inf'):\n",
    "                    discretized_ranges.append(6)\n",
    "                elif np.isnan(data.ranges[i]):\n",
    "                    discretized_ranges.append(0)\n",
    "                else:\n",
    "                    discretized_ranges.append(int(data.ranges[i]))\n",
    "            if (min_range > data.ranges[i] > 0):\n",
    "                done = True\n",
    "        return discretized_ranges,done\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def _step(self, action):\n",
    "        rospy.wait_for_service('/gazebo/unpause_physics')\n",
    "        try:\n",
    "            self.unpause()\n",
    "        except rospy.ServiceException, e:\n",
    "            print (\"/gazebo/unpause_physics service call failed\")\n",
    "        if action == 0: #FORWARD\n",
    "            vel_cmd = Twist()\n",
    "            vel_cmd.linear.x = 1.0\n",
    "            vel_cmd.angular.z = 0.0\n",
    "            self.vel_pub.publish(vel_cmd)\n",
    "        elif action == 1: #LEFT\n",
    "            vel_cmd = Twist()\n",
    "            vel_cmd.linear.x = 0.05\n",
    "            vel_cmd.angular.z = 0.3\n",
    "            self.vel_pub.publish(vel_cmd)\n",
    "        elif action == 2: #RIGHT\n",
    "            vel_cmd = Twist()\n",
    "            vel_cmd.linear.x = 0.05\n",
    "            vel_cmd.angular.z = -0.3\n",
    "            self.vel_pub.publish(vel_cmd)\n",
    "\n",
    "        data = None\n",
    "        while data is None:\n",
    "            try:\n",
    "                data = rospy.wait_for_message('/kobuki/laser/scan', LaserScan, timeout=5)\n",
    "            except:\n",
    "                print \"Time out /kobuki/laser/scan\"\n",
    "                pass\n",
    "        rospy.wait_for_service('/gazebo/pause_physics')\n",
    "        try:\n",
    "            #resp_pause = pause.call()\n",
    "            self.pause()\n",
    "        except rospy.ServiceException, e:\n",
    "            print (\"/gazebo/pause_physics service call failed\")\n",
    "\n",
    "        state,done = self.discretize_observation(data,5)\n",
    "\n",
    "        if not done:\n",
    "            if action == 0:\n",
    "                reward = 5\n",
    "            else:\n",
    "                reward = 1\n",
    "        else:\n",
    "            reward = -200\n",
    "\n",
    "        return state, reward, done, {}\n",
    "\n",
    "    def _reset(self):\n",
    "\n",
    "        # Resets the state of the environment and returns an initial observation.\n",
    "        rospy.wait_for_service('/gazebo/reset_simulation')\n",
    "        try:\n",
    "            #reset_proxy.call()\n",
    "            self.reset_proxy()\n",
    "        except rospy.ServiceException, e:\n",
    "            print (\"/gazebo/reset_simulation service call failed\")\n",
    "\n",
    "        # Unpause simulation to make observation\n",
    "        rospy.wait_for_service('/gazebo/unpause_physics')\n",
    "        try:\n",
    "            #resp_pause = pause.call()\n",
    "            self.unpause()\n",
    "        except rospy.ServiceException, e:\n",
    "            print (\"/gazebo/unpause_physics service call failed\")\n",
    "\n",
    "        #read laser data\n",
    "        data = None\n",
    "        while data is None:\n",
    "            try:\n",
    "                data = rospy.wait_for_message('/kobuki/laser/scan', LaserScan, timeout=5)\n",
    "            except:\n",
    "                print \"Something went wrong reading /kobuki/laser/scan\"\n",
    "                pass\n",
    "\n",
    "        rospy.wait_for_service('/gazebo/pause_physics')\n",
    "        try:\n",
    "            #resp_pause = pause.call()\n",
    "            self.pause()\n",
    "        except rospy.ServiceException, e:\n",
    "            print (\"/gazebo/pause_physics service call failed\")\n",
    "\n",
    "        state = self.discretize_observation(data,5) \n",
    "\n",
    "        return state\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">**my_simple_learning_turtlebot.py**</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import gym\n",
    "import time\n",
    "import numpy\n",
    "import random\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import qlearn\n",
    "# import liveplot\n",
    "from gym import wrappers\n",
    "from liveplot import LivePlot\n",
    "import rospy\n",
    "\n",
    "import my_custom_env\n",
    "\n",
    "def render():\n",
    "    render_skip = 0 #Skip first X episodes.\n",
    "    render_interval = 50 #Show render Every Y episodes.\n",
    "    render_episodes = 10 #Show Z episodes every rendering.\n",
    "\n",
    "    if (x%render_interval == 0) and (x != 0) and (x > render_skip):\n",
    "        env.render()\n",
    "    elif ((x-render_episodes)%render_interval == 0) and (x != 0) and (x > render_skip) and (render_episodes < x):\n",
    "        env.render(close=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    rospy.init_node('turtle_gym', anonymous=True)\n",
    "    env = gym.make('MyCustom-v0')\n",
    "    print \"Gym Make done\"\n",
    "    outdir = '/tmp/gazebo_gym_experiments'\n",
    "    #outdir = '/home/user/catkin_ws/src/gym_construct/src/gazebo_gym_experiments'\n",
    "    # env.monitor.start(outdir, force=True, seed=None)       # I had to comment this and\n",
    "    env = wrappers.Monitor(env, outdir, force=True)          # use this to avoid warnings\n",
    "    #plotter = LivePlot(outdir)\n",
    "    print \"Monitor Wrapper started\"\n",
    "    last_time_steps = numpy.ndarray(0)\n",
    "\n",
    "    qlearn = qlearn.QLearn(actions=range(env.action_space.n),\n",
    "                    alpha=0.1, gamma=0.8, epsilon=0.9)\n",
    "\n",
    "    initial_epsilon = qlearn.epsilon\n",
    "\n",
    "    epsilon_discount = 0.999 # 1098 eps to reach 0.1\n",
    "\n",
    "    start_time = time.time()\n",
    "    total_episodes = 10\n",
    "    highest_reward = 0\n",
    "\n",
    "    for x in range(total_episodes):\n",
    "        done = False\n",
    "\n",
    "        cumulated_reward = 0 #Should going forward give more reward then L/R ?\n",
    "        print (\"Episode = \"+str(x))\n",
    "        observation = env.reset()\n",
    "        if qlearn.epsilon > 0.05:\n",
    "            qlearn.epsilon *= epsilon_discount\n",
    "\n",
    "        #render()\n",
    "        print \"Starting Render\"\n",
    "        env.render()\n",
    "        print \"End Render\"\n",
    "        state = ''.join(map(str, observation))\n",
    "        max_range = 1000\n",
    "        for i in range(max_range):\n",
    "\n",
    "            # Pick an action based on the current state\n",
    "            action = qlearn.chooseAction(state)\n",
    "            # Execute the action and get feedback\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            cumulated_reward += reward\n",
    "            if highest_reward < cumulated_reward:\n",
    "                highest_reward = cumulated_reward\n",
    "\n",
    "            nextState = ''.join(map(str, observation))\n",
    "\n",
    "            qlearn.learn(state, action, reward, nextState)\n",
    "\n",
    "            #env.monitor.flush(force=True)\n",
    "\n",
    "            if not(done):\n",
    "                state = nextState\n",
    "            else:\n",
    "                print \"DONE\"\n",
    "                last_time_steps = numpy.append(last_time_steps, [int(i + 1)])\n",
    "                break \n",
    "\n",
    "        m, s = divmod(int(time.time() - start_time), 60)\n",
    "        h, m = divmod(m, 60)\n",
    "        print (\"EP: \"+str(x+1)+\" - [alpha: \"+str(round(qlearn.alpha,2))+\" - gamma: \"+str(round(qlearn.gamma,2))+\" - epsilon: \"+str(round(qlearn.epsilon,2))+\"] - Reward: \"+str(cumulated_reward)+\"     Time: %d:%02d:%02d\" % (h, m, s))\n",
    "\n",
    "    #Github table content\n",
    "    print (\"\\n|\"+str(total_episodes)+\"|\"+str(qlearn.alpha)+\"|\"+str(qlearn.gamma)+\"|\"+str(initial_epsilon)+\"*\"+str(epsilon_discount)+\"|\"+str(highest_reward)+\"| PICTURE |\")\n",
    "\n",
    "    l = last_time_steps.tolist()\n",
    "    l.sort()\n",
    "\n",
    "    #print(\"Parameters: a=\"+str)\n",
    "    print(\"Overall score: {:0.2f}\".format(last_time_steps.mean()))\n",
    "    print(\"Best 100 score: {:0.2f}\".format(reduce(lambda x, y: x + y, l[-100:]) / len(l[-100:])))\n",
    "\n",
    "    #env.monitor.close()\n",
    "    #env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">END Solution Exercise 2.1</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#EE9023;color:white;\">**Exercise 2.2**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is working and we have our own environment file, let's do some modifications to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>\n",
    "Change the rewards given values. For instance, make turning more rewarding than going forward. Or give going forward more weight. Can you see any changes in the emerging behaviour?<br>\n",
    "</li>\n",
    "<li>\n",
    "Change the minimum distance to a higher value to teach the robot to not get so close to walls.\n",
    "</li>\n",
    "<li>\n",
    "Change the speeds of the movements so that it goes faster forward and turns slower.<br>\n",
    "</li>\n",
    "<li>\n",
    "Implement a new action to be performed, and also add it into the learning Python script so that it is performed.\n",
    "For instance, implement a \"GO BACKARDS TURNING\" action that is executed when the robot gets too close to a wall. You will also change your own learning script to make it do that new action.<br>\n",
    "Does it get stuck or in an infinite loop?\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#EE9023;color:white;\">**END of Exercise 2.2**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Local:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that all the topics stated up until now are applicable for the standard gym module locally and the gym-gazebo locally. So, you can perform any of these actions exactly the same in your computer locally, if desired, once you download all of the required software from:\n",
    "\n",
    "<a href=\"https://github.com/erlerobot/gym-gazebo\">Gym-Gazebo-Git</a><br>\n",
    "<a href=\"https://gym.openai.com/docs\">Gym-Docs</a>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
